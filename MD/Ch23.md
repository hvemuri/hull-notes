# Ch 23 Estimating Volatilities and Correlations

## Estimating Volatility

Let $\sigma_n$ be volatility of a market variable on day $n$ as estimated at the end of day $n-1$.
The square of the volatility $\sigma_n^2$ is the **variance rate** on day $n$.

Suppose the value of the market variable at the end of day $i$ is $S_i$. 
The variable $u_i$ is the continuously compounded return during day $i$.

$$u_i = \ln \frac{S_i}{S_{i-1}}$$

An unbiased estimate of the variance rate per day using the most recent $m$ observations on the $u_i$ is given by 

$$\sigma_n^2 = \frac{1}{m-1} \sum_{i=1}^m (u_{n-i} - \bar{u})^2$$

where $\bar{u}$ is the mean of the $u_i$.

To monitor daily volatility, the formula is changed in three ways:
1. $u_i$ is defined as the percentage change in the market variable 

$$u_i = \frac{S_i - S_{i-1}}{S_{i-1}}$$

2. $\bar{u}$ is assumed to be zero
3. $m-1$ is replaced by $m$ (moves from unbiased estimate to maximum likelihood estimate)

The simplified formula for the variance rate is 

$$\sigma_n^2 = \frac{1}{m} \sum_{i=1}^m u_{n-i}^2$$

#### Weighting Schemes

The equation above gives equal weight to $u_{n-1}^2, u_{n-2}^2, \dots, u_{n-m}^2$. Since the objective is to estimate the current level of volatility, it makes sense to give more weight to more recent data.

$$\sigma_n^2 = \sum_{i=1}^m \alpha_i u_{n-i}^2$$

where $\alpha_i$ is the weight given to the observation $i$ days ago.

The $\alpha$ values should be positive, increasing (less weight to older days), and sum to 1. 

An extension of this is to assume there is a long-run average variance rate and that this should be given more weight. 

$$\sigma_n^2 = \gamma V_L + \sum_{i=1}^m \alpha_i u_{n-i}^2$$

where $V_L$ is the long-run variance rate and $\gamma$ is the weight assigned to $V_L$. 

The weights must sum to 1 so $$\gamma + \sum_{i=1}^m \alpha_i = 1$$

---

ARCH(m) model (autoregressive conditional heteroscedasticity) 

$$\sigma_n^2 = \omega + \sum_{i=1}^m \alpha_i u_{n-i}^2$$ where $\omega = \gamma V_L$. 

## The Exponentially Weighted Moving Average Model

EWMA model (exponentially weighted moving average) 

- particular case of the model (given above) $$\sigma_n^2 = \sum_{i=1}^m \alpha_i u_{n-i}^2$$
- weights decrease exponentially going back through time $$\alpha_{i+1} = \lambda \alpha_i \,\,\,\,\, \text{where} \,\,\,\,\, 0 < \lambda < 1$$

This leads to a formula for updating volatility estimates

$$\sigma_n^2 = \lambda \sigma_{n-1}^2 + (1-\lambda)u_{n-1}^2$$

- $\lambda$ governs how responsive the estimate of daily volatility is to the most recent daily percentage change 
-- low $\lambda$ means a great deal of weight is given to the $u_{n-1}^2$ term
-- high $\lambda$ means the estimate responds slowly to new information provided by daily change

## The GARCH(1, 1) Model

GARCH(1, 1) model (generalized autoregressive conditional heteroscedasticity)

$\sigma_n^2$ is calculated from a long-run average variance rate $V_L$ as well as from $\sigma_{n-1}$ and $u_{n-1}$

$$\sigma_n^2 = \gamma V_L + \alpha u_{n-1}^2 + \beta \sigma_{n-1}^2$$

where $\gamma$, $\alpha$, and $\beta$ are weights with 

$$\gamma + \alpha + \beta = 1$$

The EWMA model is a particular case of GARCH(1, 1) where $\gamma = 0$, $\alpha = 1-\lambda$, and $\beta = \lambda$.

The (1, 1) indicates that $\sigma_n^2$ is based on the most recent observations of $u^2$ and the most recent estimate of the variance rate ($\sigma^2$). 

GARCH(1, 1) can also be written 

$$\sigma_n^2 = \omega + \alpha u_{n-1}^2 + \beta \sigma_{n-1}^2$$

where $\omega = \gamma V_L$. 

Once $\omega$, $\alpha$, and $\beta$ have been estimated, calculate $\gamma$ as $1 - \alpha - \beta$, and calculate $V_L$ as $\omega / \gamma$. 

Note that $\alpha + \beta < 1$ so that $\gamma$ (weight applied to long-term variance) is not negative. 

#### The Weights

Note that the model is recursive.
Substituting for $\sigma$ shows that the weight applied to $u_{n-i}^2$ is $\alpha \beta^{i-1}$. 

The weights decline exponentially at rate $\beta$, which is the *decay rate*

- similar to $\lambda$ in the EWMA model
- relative importance of the observations on the $u_i$ in determining current variance rate 
-- Let $\beta = 0.9$
-- $u_{n-2}^2$ is 90% as important as $u_{n-1}^2$  
-- $u_{n-3}^2$ is 81% as important as $u_{n-1}^2$

GARCH(1, 1) model is similar to EWMA model 
- both have weights that decline exponentially for past $u^2$ 
- GARCH(1, 1) also assigns some weight to the long-run average volatility 

#### Mean Reversion

GARCH(1, 1) model recognizes that the variance approaches the long-run average level $V_L$ 

The weight assigned to $V_L$ is $\gamma$.

GARCH(1, 1) is equivalent to a model where the variance $V$ follows the stochastic process

$$dV = a(V_L - V) dt + \xi V \, dz$$ 

where time is measured in days, $a = 1 - \alpha - \beta$, and $\xi = \alpha \sqrt{2}$. 

This is a mean-reverting model 
- variance has a drift that pulls it back to $V_L$ at rate $a$
- when $V > V_L$, the variance has negative drift
- when $V < V_L$, the variance has positive drift 
- superimposed on the drift is a volatility $\xi$ 

## Choosing Between the Models

Variance rates tend to be mean reverting in practice. GARCH(1, 1) model incorporates mean reversion. EWMA model does not. So GARCH(1, 1) is theoretically more appealing.

When $\omega = 0$, GARCH(1, 1) reduces to EWMA. 
When $\omega < 0$, GARCH(1, 1) is not stable, so EWMA makes more sense. 

## Maximum Likelihood Methods

- how parameters in the models are estimated from historical data
- involves choosing values for the parameters that maximize the chance of the data occurring

Example

Suppose 10 stocks are sampled at random on a certain day. 
The price of one declined on that day, and the prices of the others remained or increased.

Let probability of price decline be $p$. 
Probability that a particular stock declines in price and the others do not is $P = p(1-p)^9$. 
The best estimate of $p$ is the one that maximizes $P$. 

$$\frac{dP}{dp} = (1-10p)(1-p)^8 = 0$$

$$\Rightarrow p = 0.1$$

So the maximum likelihood estimate of $p$ is $0.1$

#### Estimating a Constant Variance

Consider estimating the variance of a variable $X$ from $m$ observations on $X$ when the underlying distribution is normal with zero mean. The observations are $u_1, u_2, \dots, u_m$. 

Let the variance be $v$. 

The likelihood of $u_i$ being observed is the probability density function for $X$ when $X = u_i$ 

$$\frac{1}{\sqrt{2\pi v}} \exp \left( \frac{-u_i^2}{2v} \right)$$

The likelihood of $m$ observations occurring in the order observed is 

$$\prod_{i=1}^m \left[ \frac{1}{\sqrt{2\pi v}} \exp \left( \frac{-u_i^2}{2v} \right) \right]$$

The best estimate of $v$ is the value that maximizes this expression.

Maximizing an expression is equivalent to maximizing the logarithm of the expression.
Taking the logarithm of the above expression and ignoring constant multiplicative factors gives

$$\sum_{i=1}^m \left[ -\ln(v) - \frac{u_i^2}{v} \right]$$

which is equivalent to 

$$-m \ln(v) - \sum_{i=1}^m \frac{u_i^2}{v}$$

Differentiating this expression with respect to $v$ and setting it equal to zero gives

$$\frac{1}{m} \sum_{i=1}^m u_i^2$$

as the maximum likelihood estimator of $v$. 

#### Estimating EWMA or GARCH(1, 1) Parameters

Let $v_i = \sigma_i^2$ be the variance estimated for day $i$. 
Assume the probability distribution of $u_i$ conditional on the variance is normal. 

A similar analysis to the one above shows the best parameters are the ones that maximize

$$\prod_{i=1}^m \left[ \frac{1}{\sqrt{2\pi v_i}} \exp \left( \frac{-u_i^2}{2v_i} \right) \right]$$

which is equivalent to maximizing 

$$\sum_{i=1}^m \left[ -\ln(v_i) - \frac{u_i^2}{v_i} \right]$$

This is the same as above but with $v$ replaced by $v_i$. 
Need to search iteratively to find the parameters in the model that maximize the expression. 

---

An alternative approach to estimating parameters in GARCH(1, 1) is **variance targeting**

- involves setting long-run average variance rate $V_L$ equal to sample variance from data 
- value of $\omega$ then equals $V_L(1 - \alpha - \beta)$ so only two parameters have to be estimated

---

Estimation procedure for EWMA model is relatively simple

- set $\omega = 0, \alpha = 1-\lambda, \beta = \lambda$ so only one parameter has to be estimated 

#### How Good is the Model?

The assumption underlying GARCH is that volatility changes with the passage of time
- some periods have high volatility (when $u_i^2$ is high, $u_{i+1}^2, u_{i+2}^2, \dots$ tend to be high)
- some periods have low volatility (when $u_i^2$ is low, $u_{i+1}^2, u_{i+2}^2, \dots$ tend to be low)

This can be tested be examining the autocorrelation structure of the $u_i^2$. 

---

Assume the $u_i^2$ exhibit autocorrelation. If GARCH model is working, it should remove the autocorrelation. Test this by considering the autocorrelation structure for the variables $u_i^2 / \sigma_i^2$. 
If these show little autocorrelation, the model for $\sigma_i$ has succeeded in explaining autocorrelations in the $u_i^2$. 

---

A more scientific test is the Ljung-Box statistic. 

If a certain series has $m$ observations then the Ljung-Box statistic is

$$m \sum_{k=1}^K w_k \eta_k^2$$

where $\eta_k$ is the autocorrelation for a lag of $k$, $K$ is the number of lags considered, and 

$$w_k = \frac{m+2}{m-k}$$

## Using GARCH(1, 1) to Forecast Future Volatility

The variance rate for day $n$ using GARCH(1, 1) is 

$$\sigma_n^2 = (1-\alpha-\beta)V_L + \alpha u_{n-1}^2 + \beta \sigma_{n-1}^2$$

so that 

$$\sigma_n^2 - V_L = \alpha(u_{n-1}^2 - V_L) + \beta(\sigma_{n-1}^2 - V_L)$$

On day $n+t$ in the future

$$\sigma_{n+t}^2 - V_L = \alpha(u_{n+t-1}^2 - V_L) + \beta(\sigma_{n+t-1}^2 - V_L)$$

The expected value of $u_{n+t-1}^2$ is $\sigma_{n+t-1}^2$ so 

$$E[\sigma_{n+t}^2 - V_L] = (\alpha + \beta) E[\sigma_{n+t-1}^2 - V_L]$$

Using the equation repeatedly yields

$$E[\sigma_{n+t}^2 - V_L] = (\alpha + \beta)^t (\sigma_n^2 - V_L)$$

$$E[\sigma_{n+t}^2] = V_L + (\alpha + \beta)^t (\sigma_n^2 - V_L)$$

This equation forecasts volatility on day $n+t$ using information available at end of day $n-1$. 

In the EWMA model $\alpha + \beta = 1$ so the expected future variance rate equals the current variance rate, which is consistent with previous results. 

When $\alpha + \beta < 1$ the final term in the equation becomes smaller as $t$ increases. The variance rate exhibits mean reversion with reversion level $V_L$ and reversion rate $1-\alpha-\beta$. So the forecast of future variance rate tends towards $V_L$ as $t$ increases. 

When $\alpha + \beta > 1$ the weight given to the long-term average variance is negative, so the process is *mean fleeing* rather than mean reverting, and the process is not stable. 

#### Volatility Term Structures

Suppose it is day $n$.

Define 

$$V(t) = E(\sigma_{n+t}^2)$$

and 

$$a = \ln \frac{1}{\alpha + \beta}$$

so that the previous equations becomes 

$$V(t) = V_L + e^{-at} [V(0) - V_L]$$

In this equation $V(t)$ is an estimate of the instantaneous variance rate in $t$ days. 

The average variance rate per day between today and time $T$ is given by 

$$\frac{1}{T} \int_0^T V(t) \, dt = V_L + \frac{1 - e^{-aT}}{aT}[V(0) - V_L]$$

As $T$ increases, this approaches $V_L$. 

Let $\sigma(T)$ be the volatility per annum that should be used to price a $T$-day option under GARCH(1, 1). Assuming 252 days per year, $\sigma(T)^2$ is 252 times the average variance rate per day.

$$\sigma(T)^2 = 252 \left( V_L + \frac{1-e^{-aT}}{aT} [V(0) - V_L] \right)$$

Recall that the market prices of different options on the same asset are used to calculate a *volatility term structure*. This is the relationship between the implied volatilities of the options and their maturities. The equation above can be used to estimate a volatility term structure based on the GARCH(1, 1) model. 

When current volatility is above the long-term volatility, the GARCH(1, 1) model estimates a downward-sloping volatility term structure. 

When current volatility is below the long-term volatility, the GARCH(1, 1) model estimates an upward-sloping volatility term structure. 

#### Impact of Volatility Changes

When instantaneous volatility increases, the impact on volatility of an option is largest for short-life options and smallest for long-life options. Financial institutions use this when determining the exposure of their books to volatility changes. When calculating vega, they relate the size of the volatility increase to the maturity of the option. 

## Correlations

Correlations also play a key role in calculation of VaR. 

Correlation between two variables $X$ and $Y$ is defined as

$$\frac{\mathrm{cov}(X, Y)}{\sigma_X \sigma_Y}$$

The covariance between $X$ and $Y$ is defined as 

$$E[(X - \mu_X)(Y - \mu_Y)]$$

---

Let $x_i$ and $y_i$ be percentage changes in $X$ and $Y$ between end of day $i-1$ and end of day $i$

$$x_i = \frac{X_i - X_{i-1}}{X_{i-1}} \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, y_i = \frac{Y_i - Y_{i-1}}{Y_{i-1}}$$

The estimate of the correlation between $X$ and $Y$ on day $n$ is 

$$\frac{\mathrm{cov}_n}{\sigma_{x,n} \sigma_{y,n}}$$

Using equal weighting and assuming that the means of $x_i$ and $y_i$ are zero, the variance rates of $X$ and $Y$ can be estimated from the most recent $m$ observations as 

$$\sigma_{x,n}^2 = \frac{1}{m} \sum_{i=1}^m x_{n-i}^2 \,\,\,\,\,\,\,\,\,\, \sigma_{y,n}^2 = \frac{1}{m} \sum_{i=1}^m y_{n-i}^2$$

A similar estimate for the covariance between $X$ and $Y$ is 

$$\mathrm{cov}_n = \frac{1}{m} \sum_{i=1}^m x_{n-i} y_{n-i}$$

---

An alternative for updating covariances is an EWMA model similar to the one seen previously.

The formula for updating the covariance estimate is 

$$\mathrm{cov}_n = \lambda \mathrm{cov}_{n-1} + (1-\lambda) x_{n-1} y_{n-1}$$

As before, the lower the value of $\lambda$, the greater the weight that is given to recent observations. 

---

GARCH models can also be used for updating covariance estimates and forecasting future level of covariances. 

The GARCH(1, 1) model for updating a covariance is 

$$\mathrm{cov}_n = \omega + \alpha x_{n-1} y_{n-1} + \beta \mathrm{cov}_{n-1}$$ 

and the long-term average covariance is $\omega / (1 - \alpha - \beta)$. 

#### Consistency Condition for Covariances

A covariance matrix can be constructed after calculating all variances and covariances.

Not all covariance matrices are internally consistent. 

The consistency condition for an $N \times N$ covariance matrix $\Omega$ is 

$$\omega^\intercal \Omega \omega \ge 0$$

for all $N \times 1$ vectors $\omega$. 

A matrix that satisfies this property is **positive-semidefinite**.

---

To ensure a positive-semidefinite matrix is produced, variances and covariances should be calculated consistently. This means if variances are calculated by giving equal weight to the last $m$ data items, then the same should be done for covariances. If using the EWMA model, then the $\lambda$ parameter should be the same for calculating variances and covariances. 

---

Example of a covariance matrix that is not internally consistent 

$$
\begin{bmatrix}  
1 & 0 & 0.9\\  
0 & 1 & 0.9\\
0.9 & 0.9 & 1\\  
\end{bmatrix}
$$

- the variance of each variable is $1.0$ and the covariances are coefficients of correlation
- the first variable is highly correlated with the third variable
- the second variable is highly correlated with the third variable 
- however there is no correlation between the first and second variables 

Set $\omega = (1, 1, -1)$ to show that the matrix is not positive-semidefinite. 


